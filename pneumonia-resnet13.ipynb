{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n        print(os.path.join(dirname))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T16:11:51.056113Z","iopub.execute_input":"2022-05-19T16:11:51.056604Z","iopub.status.idle":"2022-05-19T16:12:04.931919Z","shell.execute_reply.started":"2022-05-19T16:11:51.056568Z","shell.execute_reply":"2022-05-19T16:12:04.929925Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"traindir = '../input/chest-xray-pneumonia/chest_xray/train'\ntestdir = '../input/chest-xray-pneumonia/chest_xray/test'\nvaldir = '../input/chest-xray-pneumonia/chest_xray/val'","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:35.333173Z","iopub.execute_input":"2022-05-19T16:12:35.333977Z","iopub.status.idle":"2022-05-19T16:12:35.338094Z","shell.execute_reply.started":"2022-05-19T16:12:35.333922Z","shell.execute_reply":"2022-05-19T16:12:35.337277Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import glob\n\ntrain_p = glob.glob(traindir+'/PNEUMONIA/*jpeg')\ntrain_n = glob.glob(traindir+'/NORMAL/*jpeg')\n\ndata = pd.DataFrame(np.concatenate([[0]*len(train_n), [1]*len(train_p)]), columns=[\"class\"])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:35.728412Z","iopub.execute_input":"2022-05-19T16:12:35.728910Z","iopub.status.idle":"2022-05-19T16:12:35.751601Z","shell.execute_reply.started":"2022-05-19T16:12:35.728871Z","shell.execute_reply":"2022-05-19T16:12:35.750840Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\ntrain_trnsf = transforms.Compose([transforms.RandomRotation((-20,20)),\n                                 transforms.Resize((224,224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n\ntest_trnsf = transforms.Compose([transforms.Resize((224,224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:36.318021Z","iopub.execute_input":"2022-05-19T16:12:36.318617Z","iopub.status.idle":"2022-05-19T16:12:36.323972Z","shell.execute_reply.started":"2022-05-19T16:12:36.318578Z","shell.execute_reply":"2022-05-19T16:12:36.323082Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder \ntrain_ds = ImageFolder(traindir, train_trnsf)\ntest_ds = ImageFolder(testdir, test_trnsf)\nval_ds = ImageFolder(valdir, test_trnsf)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:36.550227Z","iopub.execute_input":"2022-05-19T16:12:36.550517Z","iopub.status.idle":"2022-05-19T16:12:37.651081Z","shell.execute_reply.started":"2022-05-19T16:12:36.550483Z","shell.execute_reply":"2022-05-19T16:12:37.650337Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 64\ntrainloader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\ntestloader = DataLoader(test_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\nvalloader = DataLoader(val_ds, batch_size*2, shuffle = True, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:37.652310Z","iopub.execute_input":"2022-05-19T16:12:37.652492Z","iopub.status.idle":"2022-05-19T16:12:37.658087Z","shell.execute_reply.started":"2022-05-19T16:12:37.652469Z","shell.execute_reply":"2022-05-19T16:12:37.657155Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nimport optuna\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:37.659163Z","iopub.execute_input":"2022-05-19T16:12:37.659365Z","iopub.status.idle":"2022-05-19T16:12:37.668953Z","shell.execute_reply.started":"2022-05-19T16:12:37.659340Z","shell.execute_reply":"2022-05-19T16:12:37.668118Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    \n    def __len__(self):\n        return len(self.dl)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:37.670903Z","iopub.execute_input":"2022-05-19T16:12:37.671682Z","iopub.status.idle":"2022-05-19T16:12:37.685126Z","shell.execute_reply.started":"2022-05-19T16:12:37.671638Z","shell.execute_reply":"2022-05-19T16:12:37.684231Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\n\ntrain_dl = DeviceDataLoader(trainloader, device)\nvalid_dl = DeviceDataLoader(valloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:38.070612Z","iopub.execute_input":"2022-05-19T16:12:38.070918Z","iopub.status.idle":"2022-05-19T16:12:38.075536Z","shell.execute_reply.started":"2022-05-19T16:12:38.070884Z","shell.execute_reply":"2022-05-19T16:12:38.074896Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs,labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:38.589240Z","iopub.execute_input":"2022-05-19T16:12:38.589725Z","iopub.status.idle":"2022-05-19T16:12:38.598443Z","shell.execute_reply.started":"2022-05-19T16:12:38.589690Z","shell.execute_reply":"2022-05-19T16:12:38.597624Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n    \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 64, pool=True) # 3 x 224 x 224\n        self.conv2 = conv_block(64, 128, pool=True) # 64 x 112 x 112\n        self.res1 = nn.Sequential(conv_block(128,128), conv_block(128,128)) # 128 x 112 x 112\n        \n        self.conv3 = conv_block(128,256, pool=True) # 128 x 112 x 112\n        self.conv4 = conv_block(256,512,pool=True) # 256 x 56 x 56\n        self.res2 = nn.Sequential(conv_block(512,512), conv_block(512,512)) # 512 x 28 x 28\n        \n        self.conv5 = conv_block(512,786, pool=True) # 128 x 112 x 112\n        self.conv6 = conv_block(256,512,pool=True) # 256 x 56 x 56\n        self.res3 = nn.Sequential(conv_block(512,512), conv_block(512,512)) # 512 x 28 x 28\n        \n        self.conv7 = conv_block(128,256, pool=True) # 128 x 112 x 112\n        self.conv8 = conv_block(256,512,pool=True) # 256 x 56 x 56\n        self.res4 = nn.Sequential(conv_block(512,512), conv_block(512,512)) # 512 x 28 x 28\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(4608, num_classes)) # 512 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            out = self.res1(out) + out\n            out = self.conv3(out)\n            out = self.conv4(out)\n            out = self.res2(out) + out\n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:39.099550Z","iopub.execute_input":"2022-05-19T16:12:39.099824Z","iopub.status.idle":"2022-05-19T16:12:39.111429Z","shell.execute_reply.started":"2022-05-19T16:12:39.099793Z","shell.execute_reply":"2022-05-19T16:12:39.110477Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = to_device(ResNet9(3,2), device)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:40.280200Z","iopub.execute_input":"2022-05-19T16:12:40.280631Z","iopub.status.idle":"2022-05-19T16:12:40.504368Z","shell.execute_reply.started":"2022-05-19T16:12:40.280586Z","shell.execute_reply":"2022-05-19T16:12:40.503372Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# pip install torch_summary","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:41.098582Z","iopub.execute_input":"2022-05-19T16:12:41.098875Z","iopub.status.idle":"2022-05-19T16:12:41.102353Z","shell.execute_reply.started":"2022-05-19T16:12:41.098842Z","shell.execute_reply":"2022-05-19T16:12:41.101800Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# from torchsummary import summary\n# summary(model, input_size=(3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:41.503633Z","iopub.execute_input":"2022-05-19T16:12:41.504057Z","iopub.status.idle":"2022-05-19T16:12:41.520875Z","shell.execute_reply.started":"2022-05-19T16:12:41.504026Z","shell.execute_reply":"2022-05-19T16:12:41.519613Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\n\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:54.877347Z","iopub.execute_input":"2022-05-19T16:12:54.877736Z","iopub.status.idle":"2022-05-19T16:12:54.888430Z","shell.execute_reply.started":"2022-05-19T16:12:54.877707Z","shell.execute_reply":"2022-05-19T16:12:54.887500Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:12:56.567968Z","iopub.execute_input":"2022-05-19T16:12:56.568244Z","iopub.status.idle":"2022-05-19T16:12:59.297503Z","shell.execute_reply.started":"2022-05-19T16:12:56.568213Z","shell.execute_reply":"2022-05-19T16:12:59.296709Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"epochs = 8\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:13:00.623827Z","iopub.execute_input":"2022-05-19T16:13:00.624114Z","iopub.status.idle":"2022-05-19T16:13:00.628683Z","shell.execute_reply.started":"2022-05-19T16:13:00.624085Z","shell.execute_reply":"2022-05-19T16:13:00.628128Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n                        grad_clip = grad_clip,\n                        weight_decay = weight_decay,\n                        opt_func = opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T16:13:01.341847Z","iopub.execute_input":"2022-05-19T16:13:01.342264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs Number of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs No. of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs',[]) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch No.')\n    plt.ylabel('Learning Rate')\n    plt.title('Learning Rate vs Batch no.');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_lrs(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class block(nn.Module):\n    def __init__(\n        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n    ):\n        super(block, self).__init__()\n        self.expansion = 4\n        self.conv1 = nn.Conv2d(\n            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n        self.conv2 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n        self.conv3 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels * self.expansion,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False\n        )\n        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x.clone()\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, image_channels, num_classes):\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Essentially the entire ResNet architecture are in these 4 lines below\n        self.layer1 = self._make_layer(\n            block, layers[0], intermediate_channels=64, stride=1\n        )\n        self.layer2 = self._make_layer(\n            block, layers[1], intermediate_channels=128, stride=2\n        )\n        self.layer3 = self._make_layer(\n            block, layers[2], intermediate_channels=256, stride=2\n        )\n        self.layer4 = self._make_layer(\n            block, layers[3], intermediate_channels=512, stride=2\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * 4, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n\n        return x\n\n    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n        identity_downsample = None\n        layers = []\n\n        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n        # we need to adapt the Identity (skip connection) so it will be able to be added\n        # to the layer that's ahead\n        if stride != 1 or self.in_channels != intermediate_channels * 4:\n            identity_downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.in_channels,\n                    intermediate_channels * 4,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False\n                ),\n                nn.BatchNorm2d(intermediate_channels * 4),\n            )\n\n        layers.append(\n            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n        )\n\n        # The expansion size is always 4 for ResNet 50,101,152\n        self.in_channels = intermediate_channels * 4\n\n        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n        # and also same amount of channels.\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(self.in_channels, intermediate_channels))\n\n        return nn.Sequential(*layers)\n\n\ndef ResNet50(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n\n\ndef ResNet101(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n\n\ndef ResNet152(img_channel=3, num_classes=1000):\n    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n\n\ndef test():\n    net = ResNet101(img_channel=3, num_classes=1000)\n    y = net(torch.randn(4, 3, 224, 224)).to(\"cuda\")\n    print(y.size())\n\n\ntest()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = to_device(ResNet(block, [2,2,2,2], 3, 2), device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n                        grad_clip = grad_clip,\n                        weight_decay = weight_decay,\n                        opt_func = opt_func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}