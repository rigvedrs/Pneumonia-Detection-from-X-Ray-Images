{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#   print(dirname)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T20:34:01.702009Z","iopub.execute_input":"2022-05-23T20:34:01.702269Z","iopub.status.idle":"2022-05-23T20:34:01.706263Z","shell.execute_reply.started":"2022-05-23T20:34:01.702240Z","shell.execute_reply":"2022-05-23T20:34:01.705600Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:04.419673Z","iopub.execute_input":"2022-05-23T20:34:04.420211Z","iopub.status.idle":"2022-05-23T20:34:13.648113Z","shell.execute_reply.started":"2022-05-23T20:34:04.420174Z","shell.execute_reply":"2022-05-23T20:34:13.647187Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"traindir = '../input/chest-xray-pneumonia/chest_xray/train'\ntestdir = '../input/chest-xray-pneumonia/chest_xray/test'\nvaldir = '../input/chest-xray-pneumonia/chest_xray/val'","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:13.650338Z","iopub.execute_input":"2022-05-23T20:34:13.650630Z","iopub.status.idle":"2022-05-23T20:34:13.657015Z","shell.execute_reply.started":"2022-05-23T20:34:13.650595Z","shell.execute_reply":"2022-05-23T20:34:13.656285Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"files = next(os.walk(traindir+'/PNEUMONIA'))[2]\ntrain_count_p = len(files)\nfiles = next(os.walk(traindir+'/NORMAL'))[2]\ntrain_count_n = len(files)\nprint(\"P test Number = \", train_count_p)\nprint(\"N test number = \", train_count_n)\n\nfiles = next(os.walk(testdir+'/PNEUMONIA'))[2]\ntest_count_p = len(files)\nfiles = next(os.walk(testdir+'/NORMAL'))[2]\ntest_count_n = len(files)\nprint(\"P test Number = \", test_count_p)\nprint(\"N test number = \", test_count_n)\n\nfiles = next(os.walk(valdir+'/PNEUMONIA'))[2]\nval_count_p = len(files)\nfiles = next(os.walk(valdir+'/NORMAL'))[2]\nval_count_n = len(files)\nprint(\"P test Number = \", val_count_p)\nprint(\"N test number = \", val_count_n)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:13.658212Z","iopub.execute_input":"2022-05-23T20:34:13.658704Z","iopub.status.idle":"2022-05-23T20:34:15.199500Z","shell.execute_reply.started":"2022-05-23T20:34:13.658669Z","shell.execute_reply":"2022-05-23T20:34:15.198793Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Sample Pneumonia Images","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15, 5))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(testdir+'/PNEUMONIA', os.listdir(testdir+'/PNEUMONIA')[i]))\n    plt.title('Pneumonia')\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:15.202868Z","iopub.execute_input":"2022-05-23T20:34:15.203351Z","iopub.status.idle":"2022-05-23T20:34:16.832833Z","shell.execute_reply.started":"2022-05-23T20:34:15.203313Z","shell.execute_reply":"2022-05-23T20:34:16.832138Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(testdir+'/NORMAL', os.listdir(testdir+'/NORMAL')[i]))\n    plt.title('Normal')\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:16.836635Z","iopub.execute_input":"2022-05-23T20:34:16.838590Z","iopub.status.idle":"2022-05-23T20:34:19.473786Z","shell.execute_reply.started":"2022-05-23T20:34:16.838551Z","shell.execute_reply":"2022-05-23T20:34:19.473129Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import glob\n\ntrain_p = glob.glob(traindir+'/PNEUMONIA/*.jpeg')\ntrain_n = glob.glob(traindir+'/NORMAL/*.jpeg')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:19.475050Z","iopub.execute_input":"2022-05-23T20:34:19.475435Z","iopub.status.idle":"2022-05-23T20:34:19.500702Z","shell.execute_reply.started":"2022-05-23T20:34:19.475399Z","shell.execute_reply":"2022-05-23T20:34:19.500085Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:19.502874Z","iopub.execute_input":"2022-05-23T20:34:19.503251Z","iopub.status.idle":"2022-05-23T20:34:19.506572Z","shell.execute_reply.started":"2022-05-23T20:34:19.503214Z","shell.execute_reply":"2022-05-23T20:34:19.505801Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":" data = pd.DataFrame(np.concatenate([[0]*len(train_n) , [1]*len(train_p)]),columns=[\"class\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:19.508154Z","iopub.execute_input":"2022-05-23T20:34:19.508431Z","iopub.status.idle":"2022-05-23T20:34:19.518030Z","shell.execute_reply.started":"2022-05-23T20:34:19.508394Z","shell.execute_reply":"2022-05-23T20:34:19.517334Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Comparing Pneumonia and Normal Images","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(15,10))\nsns.countplot(data['class'], data=data, palette ='rocket')\nplt.title('PNEUMONIA VS NORMAL')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:19.519601Z","iopub.execute_input":"2022-05-23T20:34:19.519934Z","iopub.status.idle":"2022-05-23T20:34:20.423641Z","shell.execute_reply.started":"2022-05-23T20:34:19.519898Z","shell.execute_reply":"2022-05-23T20:34:20.422915Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Transforming Images \n- Resizing \n- Normalizing \n- Applying Random Rotations","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\ntrain_trnsf = transforms.Compose([transforms.RandomRotation(degrees=(-20,+20)),\n                                 transforms.Resize((256,256)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n\ntest_trnsf = transforms.Compose([transforms.Resize((256,256)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:20.426536Z","iopub.execute_input":"2022-05-23T20:34:20.427026Z","iopub.status.idle":"2022-05-23T20:34:20.625967Z","shell.execute_reply.started":"2022-05-23T20:34:20.426988Z","shell.execute_reply":"2022-05-23T20:34:20.625266Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\ntrain_ds = ImageFolder(traindir, train_trnsf)\ntest_ds = ImageFolder(testdir, test_trnsf)\nval_ds = ImageFolder(valdir, test_trnsf)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:20.627391Z","iopub.execute_input":"2022-05-23T20:34:20.627686Z","iopub.status.idle":"2022-05-23T20:34:21.588803Z","shell.execute_reply.started":"2022-05-23T20:34:20.627649Z","shell.execute_reply":"2022-05-23T20:34:21.587984Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"img, labels = train_ds[0]\nimg.shape\ntrain_ds.classes","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.592169Z","iopub.execute_input":"2022-05-23T20:34:21.592396Z","iopub.status.idle":"2022-05-23T20:34:21.754447Z","shell.execute_reply.started":"2022-05-23T20:34:21.592369Z","shell.execute_reply":"2022-05-23T20:34:21.753492Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"raw","source":"# img, label = train_ds[10]\n# plt.imshow(img.permute(1, 2, 0))\n# print('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:33:55.866267Z","iopub.execute_input":"2022-05-02T20:33:55.868406Z","iopub.status.idle":"2022-05-02T20:33:55.873523Z","shell.execute_reply.started":"2022-05-02T20:33:55.868367Z","shell.execute_reply":"2022-05-02T20:33:55.872917Z"}}},{"cell_type":"code","source":"class_names = train_ds.classes\nprint(class_names)\nprint(train_ds.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.756060Z","iopub.execute_input":"2022-05-23T20:34:21.756501Z","iopub.status.idle":"2022-05-23T20:34:21.762235Z","shell.execute_reply.started":"2022-05-23T20:34:21.756454Z","shell.execute_reply":"2022-05-23T20:34:21.761411Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 64\ntrainloader = DataLoader(train_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\ntestloader = DataLoader(test_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\nvalloader = DataLoader(val_ds, batch_size*2, shuffle = True, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.763680Z","iopub.execute_input":"2022-05-23T20:34:21.764323Z","iopub.status.idle":"2022-05-23T20:34:21.773796Z","shell.execute_reply.started":"2022-05-23T20:34:21.764280Z","shell.execute_reply":"2022-05-23T20:34:21.772885Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    \n    def __len__(self):\n        return len(self.dl)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.775329Z","iopub.execute_input":"2022-05-23T20:34:21.775712Z","iopub.status.idle":"2022-05-23T20:34:21.784171Z","shell.execute_reply.started":"2022-05-23T20:34:21.775672Z","shell.execute_reply":"2022-05-23T20:34:21.783413Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nclass SimpleResidualBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 3, stride = 1, padding = 1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 3,stride = 1, padding = 1)\n        self.relu2 = nn.ReLU()\n        \n    def forward(self,x):\n        out = self.conv1(x)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        out = self.relu2(out)\n        return out + x","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.785652Z","iopub.execute_input":"2022-05-23T20:34:21.786315Z","iopub.status.idle":"2022-05-23T20:34:21.795257Z","shell.execute_reply.started":"2022-05-23T20:34:21.786247Z","shell.execute_reply":"2022-05-23T20:34:21.794452Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.796315Z","iopub.execute_input":"2022-05-23T20:34:21.797018Z","iopub.status.idle":"2022-05-23T20:34:21.862908Z","shell.execute_reply.started":"2022-05-23T20:34:21.796982Z","shell.execute_reply":"2022-05-23T20:34:21.862063Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(trainloader, device)\nvalid_dl = DeviceDataLoader(valloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.864490Z","iopub.execute_input":"2022-05-23T20:34:21.864804Z","iopub.status.idle":"2022-05-23T20:34:21.870816Z","shell.execute_reply.started":"2022-05-23T20:34:21.864767Z","shell.execute_reply":"2022-05-23T20:34:21.869632Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"simple_resnet = to_device(SimpleResidualBlock(), device)\ncount = 0\n\nfor images,labels in train_dl:\n    out = simple_resnet(images)\n    print(out.shape)\n    print(count+1)\n    break\n    \ndel simple_resnet, images, labels\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:21.872211Z","iopub.execute_input":"2022-05-23T20:34:21.872480Z","iopub.status.idle":"2022-05-23T20:34:34.196770Z","shell.execute_reply.started":"2022-05-23T20:34:21.872442Z","shell.execute_reply":"2022-05-23T20:34:34.195821Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs,labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:34.198383Z","iopub.execute_input":"2022-05-23T20:34:34.198735Z","iopub.status.idle":"2022-05-23T20:34:34.210739Z","shell.execute_reply.started":"2022-05-23T20:34:34.198692Z","shell.execute_reply":"2022-05-23T20:34:34.209932Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Trying ResNet 9 model \n\nCould not compromise with the size of the x ray image since there are very minute details in the X-ray that have to be taken into consideration. So ended up requiring large number of neurons in the final neural network.\nThis resulted in high fluctuation of accuracy during training.\n\n\n","metadata":{}},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n    \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 64, pool=True) # 64 x 64 x 128 x 128\n        self.conv2 = conv_block(64, 128, pool=True) # 64 x 128 x 64 x 64\n        self.res1 = nn.Sequential(conv_block(128,128), conv_block(128,128)) # 64 x 128 x 64 x 64\n        \n        self.conv3 = conv_block(128,256, pool=True) # 64 x 256 x 32 x 32\n        self.conv4 = conv_block(256,512,pool=True) # 64 x 512 x 16 x 16\n        self.res2 = nn.Sequential(conv_block(512,512), conv_block(512,512)) # 64 x 512 x 16 x 16\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(8192, num_classes)) # 512 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            out = self.res1(out) + out\n            out = self.conv3(out)\n            out = self.conv4(out)\n            out = self.res2(out) + out\n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-03T12:04:44.977553Z","iopub.execute_input":"2022-05-03T12:04:44.977842Z","iopub.status.idle":"2022-05-03T12:04:44.989829Z","shell.execute_reply.started":"2022-05-03T12:04:44.977803Z","shell.execute_reply":"2022-05-03T12:04:44.989154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Tried decreasing the number of channels and removing a Max pooling layer in the beginning. \n> Received the same number of parameters in the end (8192), so increased the number of layers in the neural network.\n> There was longer training time and the accuracy kept fluctuating again**\n","metadata":{}},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n    \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 16) # 64 x 16 x 256 x 256\n        self.conv2 = conv_block(16, 32, pool=True) # 64 x 32 x 64 x 64\n        self.res1 = nn.Sequential(conv_block(32,32), conv_block(32,32)) # 64 x 32 x 64 x 64\n        \n        self.conv3 = conv_block(32,64, pool=True) # 64 x 64 x 32 x 32\n        self.conv4 = conv_block(64,128,pool=True) # 64 x 128 x 16 x 16\n        self.res2 = nn.Sequential(conv_block(128,128), conv_block(128,128)) # 64 x 128 x 16 x 16\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(8192, 4096),\n                                       nn.Linear(4096,128),\n                                       nn.Linear(128, num_classes)) # 128 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            out = self.res1(out) + out\n            out = self.conv3(out)\n            out = self.conv4(out)\n            out = self.res2(out) + out\n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:37.335359Z","iopub.execute_input":"2022-05-23T12:45:37.336239Z","iopub.status.idle":"2022-05-23T12:45:37.348337Z","shell.execute_reply.started":"2022-05-23T12:45:37.336188Z","shell.execute_reply":"2022-05-23T12:45:37.347524Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = to_device(ResNet9(3,2), device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:39.569179Z","iopub.execute_input":"2022-05-23T12:45:39.569744Z","iopub.status.idle":"2022-05-23T12:45:39.901842Z","shell.execute_reply.started":"2022-05-23T12:45:39.569705Z","shell.execute_reply":"2022-05-23T12:45:39.901041Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Trying another custom CNN model","metadata":{}},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\nclass CNN(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.conv1 = conv_block(in_channels, 32) # 64 x 32 x 256 x 256\n        self.conv2 = conv_block(32, 64, pool=True) # 64 x 64 x 64 x 64\n                \n        self.conv3 = conv_block(64,128, pool=True) # 64 x 128 x 32 x 32\n        self.conv4 = conv_block(128,256,pool=True) # 64 x 256 x 16 x 16\n        \n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(16384, 4096),\n                                       nn.Linear(4096,128),\n                                       nn.Linear(128, num_classes)) # 128 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            \n            out = self.conv3(out)\n            out = self.conv4(out)\n            \n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:34.215205Z","iopub.execute_input":"2022-05-23T20:34:34.215404Z","iopub.status.idle":"2022-05-23T20:34:34.226878Z","shell.execute_reply.started":"2022-05-23T20:34:34.215375Z","shell.execute_reply":"2022-05-23T20:34:34.226185Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs,labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:39.253877Z","iopub.execute_input":"2022-05-23T20:34:39.254461Z","iopub.status.idle":"2022-05-23T20:34:39.265907Z","shell.execute_reply.started":"2022-05-23T20:34:39.254420Z","shell.execute_reply":"2022-05-23T20:34:39.265020Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = to_device(CNN(3,2), device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:43.535162Z","iopub.execute_input":"2022-05-23T20:34:43.535864Z","iopub.status.idle":"2022-05-23T20:34:44.166735Z","shell.execute_reply.started":"2022-05-23T20:34:43.535829Z","shell.execute_reply":"2022-05-23T20:34:44.165988Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size=(3, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:49.211450Z","iopub.execute_input":"2022-05-23T20:34:49.211900Z","iopub.status.idle":"2022-05-23T20:34:50.308990Z","shell.execute_reply.started":"2022-05-23T20:34:49.211866Z","shell.execute_reply":"2022-05-23T20:34:50.308240Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\n\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:50.311458Z","iopub.execute_input":"2022-05-23T20:34:50.311737Z","iopub.status.idle":"2022-05-23T20:34:50.322708Z","shell.execute_reply.started":"2022-05-23T20:34:50.311701Z","shell.execute_reply":"2022-05-23T20:34:50.321632Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:52.956814Z","iopub.execute_input":"2022-05-23T20:34:52.957087Z","iopub.status.idle":"2022-05-23T20:34:53.508420Z","shell.execute_reply.started":"2022-05-23T20:34:52.957055Z","shell.execute_reply":"2022-05-23T20:34:53.507653Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"[model.validation_step(batch) for batch in valid_dl]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:34:57.483603Z","iopub.execute_input":"2022-05-23T20:34:57.483880Z","iopub.status.idle":"2022-05-23T20:34:57.946002Z","shell.execute_reply.started":"2022-05-23T20:34:57.483849Z","shell.execute_reply":"2022-05-23T20:34:57.945041Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"epochs = 8\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:35:01.416686Z","iopub.execute_input":"2022-05-23T20:35:01.417599Z","iopub.status.idle":"2022-05-23T20:35:01.423183Z","shell.execute_reply.started":"2022-05-23T20:35:01.417559Z","shell.execute_reply":"2022-05-23T20:35:01.422440Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n                        grad_clip = grad_clip,\n                        weight_decay = weight_decay,\n                        opt_func = opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T20:35:24.347161Z","iopub.execute_input":"2022-05-23T20:35:24.347834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the accuracies","metadata":{}},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs Number of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the losses","metadata":{}},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs No. of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting the learning rates, since we used weight decay","metadata":{}},{"cell_type":"code","source":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs',[]) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch No.')\n    plt.ylabel('Learning Rate')\n    plt.title('Learning Rate vs Batch no.');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_lrs(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds = torch.max(yb, dim=1)\n    return train_ds.classes[preds[0].item()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = val_ds[0]\nplt.imshow(img.permute(1,2,0).clamp(0,1))\nprint('Label', train_ds.classes[label], ',Predicted', predict_image(img, model))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = val_ds[11]\nplt.imshow(img.permute(1,2,0))\nprint('Label:', val_ds.classes[label])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = val_ds[6]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet9.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}