{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#   print(dirname)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T12:29:34.467606Z","iopub.execute_input":"2022-05-23T12:29:34.467894Z","iopub.status.idle":"2022-05-23T12:29:34.495075Z","shell.execute_reply.started":"2022-05-23T12:29:34.467819Z","shell.execute_reply":"2022-05-23T12:29:34.494430Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:34.496614Z","iopub.execute_input":"2022-05-23T12:29:34.496871Z","iopub.status.idle":"2022-05-23T12:29:43.763946Z","shell.execute_reply.started":"2022-05-23T12:29:34.496835Z","shell.execute_reply":"2022-05-23T12:29:43.763055Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"traindir = '../input/chest-xray-pneumonia/chest_xray/train'\ntestdir = '../input/chest-xray-pneumonia/chest_xray/test'\nvaldir = '../input/chest-xray-pneumonia/chest_xray/val'","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:43.767317Z","iopub.execute_input":"2022-05-23T12:29:43.767544Z","iopub.status.idle":"2022-05-23T12:29:43.773683Z","shell.execute_reply.started":"2022-05-23T12:29:43.767518Z","shell.execute_reply":"2022-05-23T12:29:43.773017Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"files = next(os.walk(traindir+'/PNEUMONIA'))[2]\ntrain_count_p = len(files)\nfiles = next(os.walk(traindir+'/NORMAL'))[2]\ntrain_count_n = len(files)\nprint(\"P test Number = \", train_count_p)\nprint(\"N test number = \", train_count_n)\n\nfiles = next(os.walk(testdir+'/PNEUMONIA'))[2]\ntest_count_p = len(files)\nfiles = next(os.walk(testdir+'/NORMAL'))[2]\ntest_count_n = len(files)\nprint(\"P test Number = \", test_count_p)\nprint(\"N test number = \", test_count_n)\n\nfiles = next(os.walk(valdir+'/PNEUMONIA'))[2]\nval_count_p = len(files)\nfiles = next(os.walk(valdir+'/NORMAL'))[2]\nval_count_n = len(files)\nprint(\"P test Number = \", val_count_p)\nprint(\"N test number = \", val_count_n)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:43.775094Z","iopub.execute_input":"2022-05-23T12:29:43.775324Z","iopub.status.idle":"2022-05-23T12:29:47.054452Z","shell.execute_reply.started":"2022-05-23T12:29:43.775292Z","shell.execute_reply":"2022-05-23T12:29:47.053642Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Sample Pneumonia Images","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15, 5))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(testdir+'/PNEUMONIA', os.listdir(testdir+'/PNEUMONIA')[i]))\n    plt.title('Pneumonia')\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:47.056537Z","iopub.execute_input":"2022-05-23T12:29:47.056779Z","iopub.status.idle":"2022-05-23T12:29:48.764153Z","shell.execute_reply.started":"2022-05-23T12:29:47.056746Z","shell.execute_reply":"2022-05-23T12:29:48.763415Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(testdir+'/NORMAL', os.listdir(testdir+'/NORMAL')[i]))\n    plt.title('Normal')\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:48.765120Z","iopub.execute_input":"2022-05-23T12:29:48.765329Z","iopub.status.idle":"2022-05-23T12:29:51.195452Z","shell.execute_reply.started":"2022-05-23T12:29:48.765302Z","shell.execute_reply":"2022-05-23T12:29:51.194804Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import glob\n\ntrain_p = glob.glob(traindir+'/PNEUMONIA/*.jpeg')\ntrain_n = glob.glob(traindir+'/NORMAL/*.jpeg')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:51.196771Z","iopub.execute_input":"2022-05-23T12:29:51.197224Z","iopub.status.idle":"2022-05-23T12:29:51.221174Z","shell.execute_reply.started":"2022-05-23T12:29:51.197189Z","shell.execute_reply":"2022-05-23T12:29:51.220563Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:51.222454Z","iopub.execute_input":"2022-05-23T12:29:51.222697Z","iopub.status.idle":"2022-05-23T12:29:51.227537Z","shell.execute_reply.started":"2022-05-23T12:29:51.222664Z","shell.execute_reply":"2022-05-23T12:29:51.226849Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":" data = pd.DataFrame(np.concatenate([[0]*len(train_n) , [1]*len(train_p)]),columns=[\"class\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:51.228645Z","iopub.execute_input":"2022-05-23T12:29:51.228948Z","iopub.status.idle":"2022-05-23T12:29:51.237509Z","shell.execute_reply.started":"2022-05-23T12:29:51.228912Z","shell.execute_reply":"2022-05-23T12:29:51.236808Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Comparing Pneumonia and Normal Images","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(15,10))\nsns.countplot(data['class'], data=data, palette ='rocket')\nplt.title('PNEUMONIA VS NORMAL')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:51.238691Z","iopub.execute_input":"2022-05-23T12:29:51.239067Z","iopub.status.idle":"2022-05-23T12:29:52.208548Z","shell.execute_reply.started":"2022-05-23T12:29:51.239029Z","shell.execute_reply":"2022-05-23T12:29:52.207827Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Transforming Images \n- Resizing \n- Normalizing \n- Applying Random Rotations","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\ntrain_trnsf = transforms.Compose([transforms.RandomRotation(degrees=(-20,+20)),\n                                 transforms.Resize((256,256)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n\ntest_trnsf = transforms.Compose([transforms.Resize((256,256)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:52.211545Z","iopub.execute_input":"2022-05-23T12:29:52.212063Z","iopub.status.idle":"2022-05-23T12:29:53.996681Z","shell.execute_reply.started":"2022-05-23T12:29:52.212028Z","shell.execute_reply":"2022-05-23T12:29:53.995893Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\ntrain_ds = ImageFolder(traindir, train_trnsf)\ntest_ds = ImageFolder(testdir, test_trnsf)\nval_ds = ImageFolder(valdir, test_trnsf)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:53.998073Z","iopub.execute_input":"2022-05-23T12:29:53.998312Z","iopub.status.idle":"2022-05-23T12:29:54.847509Z","shell.execute_reply.started":"2022-05-23T12:29:53.998279Z","shell.execute_reply":"2022-05-23T12:29:54.846779Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"img, labels = train_ds[0]\nimg.shape\ntrain_ds.classes","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:54.850659Z","iopub.execute_input":"2022-05-23T12:29:54.850881Z","iopub.status.idle":"2022-05-23T12:29:54.998535Z","shell.execute_reply.started":"2022-05-23T12:29:54.850854Z","shell.execute_reply":"2022-05-23T12:29:54.997817Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"raw","source":"# img, label = train_ds[10]\n# plt.imshow(img.permute(1, 2, 0))\n# print('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:33:55.866267Z","iopub.execute_input":"2022-05-02T20:33:55.868406Z","iopub.status.idle":"2022-05-02T20:33:55.873523Z","shell.execute_reply.started":"2022-05-02T20:33:55.868367Z","shell.execute_reply":"2022-05-02T20:33:55.872917Z"}}},{"cell_type":"code","source":"class_names = train_ds.classes\nprint(class_names)\nprint(train_ds.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:54.999636Z","iopub.execute_input":"2022-05-23T12:29:54.999891Z","iopub.status.idle":"2022-05-23T12:29:55.006018Z","shell.execute_reply.started":"2022-05-23T12:29:54.999855Z","shell.execute_reply":"2022-05-23T12:29:55.005225Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 64\ntrainloader = DataLoader(train_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\ntestloader = DataLoader(test_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\nvalloader = DataLoader(val_ds, batch_size*2, shuffle = True, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:55.007508Z","iopub.execute_input":"2022-05-23T12:29:55.008027Z","iopub.status.idle":"2022-05-23T12:29:55.014494Z","shell.execute_reply.started":"2022-05-23T12:29:55.007991Z","shell.execute_reply":"2022-05-23T12:29:55.013806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    \n    def __len__(self):\n        return len(self.dl)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:55.015930Z","iopub.execute_input":"2022-05-23T12:29:55.016563Z","iopub.status.idle":"2022-05-23T12:29:55.026755Z","shell.execute_reply.started":"2022-05-23T12:29:55.016529Z","shell.execute_reply":"2022-05-23T12:29:55.025986Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nclass SimpleResidualBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 3, stride = 1, padding = 1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 3,stride = 1, padding = 1)\n        self.relu2 = nn.ReLU()\n        \n    def forward(self,x):\n        out = self.conv1(x)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        out = self.relu2(out)\n        return out + x","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:29:55.028198Z","iopub.execute_input":"2022-05-23T12:29:55.028750Z","iopub.status.idle":"2022-05-23T12:29:55.037345Z","shell.execute_reply.started":"2022-05-23T12:29:55.028712Z","shell.execute_reply":"2022-05-23T12:29:55.036574Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:07.928290Z","iopub.execute_input":"2022-05-23T12:45:07.928572Z","iopub.status.idle":"2022-05-23T12:45:07.991602Z","shell.execute_reply.started":"2022-05-23T12:45:07.928541Z","shell.execute_reply":"2022-05-23T12:45:07.990811Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_dl = DeviceDataLoader(trainloader, device)\nvalid_dl = DeviceDataLoader(valloader, device)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:09.574713Z","iopub.execute_input":"2022-05-23T12:45:09.575253Z","iopub.status.idle":"2022-05-23T12:45:09.579427Z","shell.execute_reply.started":"2022-05-23T12:45:09.575214Z","shell.execute_reply":"2022-05-23T12:45:09.578666Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"simple_resnet = to_device(SimpleResidualBlock(), device)\ncount = 0\n\nfor images,labels in train_dl:\n    out = simple_resnet(images)\n    print(out.shape)\n    print(count+1)\n    break\n    \ndel simple_resnet, images, labels\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:11.226710Z","iopub.execute_input":"2022-05-23T12:45:11.227434Z","iopub.status.idle":"2022-05-23T12:45:22.506926Z","shell.execute_reply.started":"2022-05-23T12:45:11.227398Z","shell.execute_reply":"2022-05-23T12:45:22.506180Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs,labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:22.509105Z","iopub.execute_input":"2022-05-23T12:45:22.509368Z","iopub.status.idle":"2022-05-23T12:45:22.519629Z","shell.execute_reply.started":"2022-05-23T12:45:22.509333Z","shell.execute_reply":"2022-05-23T12:45:22.518432Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Trying ResNet 9 model \n\nCould not compromise with the size of the x ray image since there are very minute details in the X-ray that have to be taken into consideration. So ended up requiring large number of neurons in the final neural network.\nThis resulted in high fluctuation of accuracy during training.\n\n\n","metadata":{}},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n    \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 64, pool=True) # 64 x 64 x 128 x 128\n        self.conv2 = conv_block(64, 128, pool=True) # 64 x 128 x 64 x 64\n        self.res1 = nn.Sequential(conv_block(128,128), conv_block(128,128)) # 64 x 128 x 64 x 64\n        \n        self.conv3 = conv_block(128,256, pool=True) # 64 x 256 x 32 x 32\n        self.conv4 = conv_block(256,512,pool=True) # 64 x 512 x 16 x 16\n        self.res2 = nn.Sequential(conv_block(512,512), conv_block(512,512)) # 64 x 512 x 16 x 16\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(8192, num_classes)) # 512 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            out = self.res1(out) + out\n            out = self.conv3(out)\n            out = self.conv4(out)\n            out = self.res2(out) + out\n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-03T12:04:44.977553Z","iopub.execute_input":"2022-05-03T12:04:44.977842Z","iopub.status.idle":"2022-05-03T12:04:44.989829Z","shell.execute_reply.started":"2022-05-03T12:04:44.977803Z","shell.execute_reply":"2022-05-03T12:04:44.989154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Tried decreasing the number of channels and removing a Max pooling layer in the beginning. \n> Received the same number of parameters in the end (8192), so increased the number of layers in the neural network.\n> There was longer training time and the accuracy kept fluctuating again**\n","metadata":{}},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n    \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 16) # 64 x 16 x 256 x 256\n        self.conv2 = conv_block(16, 32, pool=True) # 64 x 32 x 64 x 64\n        self.res1 = nn.Sequential(conv_block(32,32), conv_block(32,32)) # 64 x 32 x 64 x 64\n        \n        self.conv3 = conv_block(32,64, pool=True) # 64 x 64 x 32 x 32\n        self.conv4 = conv_block(64,128,pool=True) # 64 x 128 x 16 x 16\n        self.res2 = nn.Sequential(conv_block(128,128), conv_block(128,128)) # 64 x 128 x 16 x 16\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(8192, 4096),\n                                       nn.Linear(4096,128),\n                                       nn.Linear(128, num_classes)) # 128 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            out = self.res1(out) + out\n            out = self.conv3(out)\n            out = self.conv4(out)\n            out = self.res2(out) + out\n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:37.335359Z","iopub.execute_input":"2022-05-23T12:45:37.336239Z","iopub.status.idle":"2022-05-23T12:45:37.348337Z","shell.execute_reply.started":"2022-05-23T12:45:37.336188Z","shell.execute_reply":"2022-05-23T12:45:37.347524Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = to_device(ResNet9(3,2), device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:39.569179Z","iopub.execute_input":"2022-05-23T12:45:39.569744Z","iopub.status.idle":"2022-05-23T12:45:39.901842Z","shell.execute_reply.started":"2022-05-23T12:45:39.569705Z","shell.execute_reply":"2022-05-23T12:45:39.901041Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs,labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item()/len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:45:55.317144Z","iopub.execute_input":"2022-05-23T12:45:55.317404Z","iopub.status.idle":"2022-05-23T12:45:55.328018Z","shell.execute_reply.started":"2022-05-23T12:45:55.317370Z","shell.execute_reply":"2022-05-23T12:45:55.327232Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"Trying another custom CNN model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block(in_channels,  out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\nclass CNN(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.conv1 = conv_block(in_channels, 32) # 64 x 32 x 256 x 256\n        self.conv2 = conv_block(32, 64, pool=True) # 64 x 64 x 64 x 64\n                \n        self.conv3 = conv_block(64,128, pool=True) # 64 x 128 x 32 x 32\n        self.conv4 = conv_block(128,256,pool=True) # 64 x 256 x 16 x 16\n        \n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(16384, 4096),\n                                       nn.Linear(4096,128),\n                                       nn.Linear(128, num_classes)) # 128 x 4 x 4\n        \n    def forward(self, xb):\n            out = self.conv1(xb)\n            out = self.conv2(out)\n            \n            out = self.conv3(out)\n            out = self.conv4(out)\n            \n            out = self.classifier(out)\n            return out","metadata":{"execution":{"iopub.status.busy":"2022-05-03T17:07:10.860333Z","iopub.execute_input":"2022-05-03T17:07:10.861191Z","iopub.status.idle":"2022-05-03T17:07:10.872549Z","shell.execute_reply.started":"2022-05-03T17:07:10.861136Z","shell.execute_reply":"2022-05-03T17:07:10.871846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = to_device(CNN(3,2), device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-05-03T17:07:11.348191Z","iopub.execute_input":"2022-05-03T17:07:11.349038Z","iopub.status.idle":"2022-05-03T17:07:11.976474Z","shell.execute_reply.started":"2022-05-03T17:07:11.34899Z","shell.execute_reply":"2022-05-03T17:07:11.975678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size=(3, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T17:07:11.977932Z","iopub.execute_input":"2022-05-03T17:07:11.978265Z","iopub.status.idle":"2022-05-03T17:07:12.687847Z","shell.execute_reply.started":"2022-05-03T17:07:11.978226Z","shell.execute_reply":"2022-05-03T17:07:12.68712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\n\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:46:07.966332Z","iopub.execute_input":"2022-05-23T12:46:07.966597Z","iopub.status.idle":"2022-05-23T12:46:07.977371Z","shell.execute_reply.started":"2022-05-23T12:46:07.966568Z","shell.execute_reply":"2022-05-23T12:46:07.976555Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:46:10.962397Z","iopub.execute_input":"2022-05-23T12:46:10.962656Z","iopub.status.idle":"2022-05-23T12:46:12.405608Z","shell.execute_reply.started":"2022-05-23T12:46:10.962628Z","shell.execute_reply":"2022-05-23T12:46:12.404807Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"[model.validation_step(batch) for batch in valid_dl]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T17:07:28.362793Z","iopub.execute_input":"2022-05-03T17:07:28.363326Z","iopub.status.idle":"2022-05-03T17:07:28.875631Z","shell.execute_reply.started":"2022-05-03T17:07:28.363286Z","shell.execute_reply":"2022-05-03T17:07:28.874449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 8\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:46:24.185814Z","iopub.execute_input":"2022-05-23T12:46:24.186100Z","iopub.status.idle":"2022-05-23T12:46:24.190582Z","shell.execute_reply.started":"2022-05-23T12:46:24.186069Z","shell.execute_reply":"2022-05-23T12:46:24.189944Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl,\n                        grad_clip = grad_clip,\n                        weight_decay = weight_decay,\n                        opt_func = opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T12:46:27.462584Z","iopub.execute_input":"2022-05-23T12:46:27.463012Z","iopub.status.idle":"2022-05-23T13:00:45.994470Z","shell.execute_reply.started":"2022-05-23T12:46:27.462954Z","shell.execute_reply":"2022-05-23T13:00:45.993033Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the accuracies","metadata":{}},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs Number of epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:45.997934Z","iopub.execute_input":"2022-05-23T13:00:45.998196Z","iopub.status.idle":"2022-05-23T13:00:46.003495Z","shell.execute_reply.started":"2022-05-23T13:00:45.998168Z","shell.execute_reply":"2022-05-23T13:00:46.002809Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.004694Z","iopub.execute_input":"2022-05-23T13:00:46.005122Z","iopub.status.idle":"2022-05-23T13:00:46.215489Z","shell.execute_reply.started":"2022-05-23T13:00:46.005086Z","shell.execute_reply":"2022-05-23T13:00:46.214803Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the losses","metadata":{}},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs No. of epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.217588Z","iopub.execute_input":"2022-05-23T13:00:46.218068Z","iopub.status.idle":"2022-05-23T13:00:46.223787Z","shell.execute_reply.started":"2022-05-23T13:00:46.218029Z","shell.execute_reply":"2022-05-23T13:00:46.222991Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.225125Z","iopub.execute_input":"2022-05-23T13:00:46.225447Z","iopub.status.idle":"2022-05-23T13:00:46.436865Z","shell.execute_reply.started":"2022-05-23T13:00:46.225404Z","shell.execute_reply":"2022-05-23T13:00:46.436196Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Plotting the learning rates, since we used weight decay","metadata":{}},{"cell_type":"code","source":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs',[]) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch No.')\n    plt.ylabel('Learning Rate')\n    plt.title('Learning Rate vs Batch no.');","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.437985Z","iopub.execute_input":"2022-05-23T13:00:46.438530Z","iopub.status.idle":"2022-05-23T13:00:46.444646Z","shell.execute_reply.started":"2022-05-23T13:00:46.438489Z","shell.execute_reply":"2022-05-23T13:00:46.443853Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"plot_lrs(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.445858Z","iopub.execute_input":"2022-05-23T13:00:46.446447Z","iopub.status.idle":"2022-05-23T13:00:46.653882Z","shell.execute_reply.started":"2022-05-23T13:00:46.446412Z","shell.execute_reply":"2022-05-23T13:00:46.650882Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds = torch.max(yb, dim=1)\n    return train_ds.classes[preds[0].item()]","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.656284Z","iopub.execute_input":"2022-05-23T13:00:46.656926Z","iopub.status.idle":"2022-05-23T13:00:46.662651Z","shell.execute_reply.started":"2022-05-23T13:00:46.656878Z","shell.execute_reply":"2022-05-23T13:00:46.662020Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"img, label = val_ds[0]\nplt.imshow(img.permute(1,2,0).clamp(0,1))\nprint('Label', train_ds.classes[label], ',Predicted', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.664061Z","iopub.execute_input":"2022-05-23T13:00:46.664526Z","iopub.status.idle":"2022-05-23T13:00:46.913510Z","shell.execute_reply.started":"2022-05-23T13:00:46.664487Z","shell.execute_reply":"2022-05-23T13:00:46.912816Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"img, label = val_ds[11]\nplt.imshow(img.permute(1,2,0))\nprint('Label:', val_ds.classes[label])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:46.915811Z","iopub.execute_input":"2022-05-23T13:00:46.916574Z","iopub.status.idle":"2022-05-23T13:00:47.137097Z","shell.execute_reply.started":"2022-05-23T13:00:46.916534Z","shell.execute_reply":"2022-05-23T13:00:47.136403Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"img, label = val_ds[6]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', train_ds.classes[label], ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T13:00:47.138333Z","iopub.execute_input":"2022-05-23T13:00:47.138677Z","iopub.status.idle":"2022-05-23T13:00:47.367432Z","shell.execute_reply.started":"2022-05-23T13:00:47.138639Z","shell.execute_reply":"2022-05-23T13:00:47.366770Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet9.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T17:21:19.737597Z","iopub.execute_input":"2022-05-03T17:21:19.737873Z","iopub.status.idle":"2022-05-03T17:21:20.458391Z","shell.execute_reply.started":"2022-05-03T17:21:19.737835Z","shell.execute_reply":"2022-05-03T17:21:20.457638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}