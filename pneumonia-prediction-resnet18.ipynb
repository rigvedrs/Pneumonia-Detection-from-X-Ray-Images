{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n        print(os.path.join(dirname))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-22T11:38:20.920662Z","iopub.execute_input":"2022-05-22T11:38:20.920963Z","iopub.status.idle":"2022-05-22T11:38:32.974457Z","shell.execute_reply.started":"2022-05-22T11:38:20.920886Z","shell.execute_reply":"2022-05-22T11:38:32.973678Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"traindir = '../input/chest-xray-pneumonia/chest_xray/train'\ntestdir = '../input/chest-xray-pneumonia/chest_xray/test'\nvaldir = '../input/chest-xray-pneumonia/chest_xray/val'","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:32.975950Z","iopub.execute_input":"2022-05-22T11:38:32.976162Z","iopub.status.idle":"2022-05-22T11:38:32.981935Z","shell.execute_reply.started":"2022-05-22T11:38:32.976131Z","shell.execute_reply":"2022-05-22T11:38:32.981090Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nimport optuna\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:32.983488Z","iopub.execute_input":"2022-05-22T11:38:32.984276Z","iopub.status.idle":"2022-05-22T11:38:36.027611Z","shell.execute_reply.started":"2022-05-22T11:38:32.984241Z","shell.execute_reply":"2022-05-22T11:38:36.026747Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import glob\n\ntrain_p = glob.glob(traindir+'/PNEUMONIA/*jpeg')\ntrain_n = glob.glob(traindir+'/NORMAL/*jpeg')\n\ndata = pd.DataFrame(np.concatenate([[0]*len(train_n), [1]*len(train_p)]), columns=[\"class\"])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:36.030034Z","iopub.execute_input":"2022-05-22T11:38:36.030349Z","iopub.status.idle":"2022-05-22T11:38:36.057795Z","shell.execute_reply.started":"2022-05-22T11:38:36.030308Z","shell.execute_reply":"2022-05-22T11:38:36.057113Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\ntrain_trnsf = transforms.Compose([transforms.RandomRotation((-20,20)),\n                                 transforms.Resize((224,224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n\ntest_trnsf = transforms.Compose([transforms.Resize((224,224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:36.059101Z","iopub.execute_input":"2022-05-22T11:38:36.059342Z","iopub.status.idle":"2022-05-22T11:38:36.265885Z","shell.execute_reply.started":"2022-05-22T11:38:36.059310Z","shell.execute_reply":"2022-05-22T11:38:36.265171Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder \ntrain_ds = ImageFolder(traindir, train_trnsf)\ntest_ds = ImageFolder(testdir, test_trnsf)\nval_ds = ImageFolder(valdir, test_trnsf)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:36.267265Z","iopub.execute_input":"2022-05-22T11:38:36.267518Z","iopub.status.idle":"2022-05-22T11:38:37.063001Z","shell.execute_reply.started":"2022-05-22T11:38:36.267484Z","shell.execute_reply":"2022-05-22T11:38:37.062289Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset = []\ndataset = torch.utils.data.ConcatDataset([dataset, train_ds])\ndataset = torch.utils.data.ConcatDataset([dataset, test_ds])\ndataset = torch.utils.data.ConcatDataset([dataset, val_ds])","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.064368Z","iopub.execute_input":"2022-05-22T11:38:37.064653Z","iopub.status.idle":"2022-05-22T11:38:37.070191Z","shell.execute_reply.started":"2022-05-22T11:38:37.064619Z","shell.execute_reply":"2022-05-22T11:38:37.069522Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 64\ntrainloader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\ntestloader = DataLoader(test_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\nvalloader = DataLoader(val_ds, batch_size*2, shuffle = True, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.071671Z","iopub.execute_input":"2022-05-22T11:38:37.072136Z","iopub.status.idle":"2022-05-22T11:38:37.079221Z","shell.execute_reply.started":"2022-05-22T11:38:37.072099Z","shell.execute_reply":"2022-05-22T11:38:37.078392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\ndef plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs Number of epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.080497Z","iopub.execute_input":"2022-05-22T11:38:37.080826Z","iopub.status.idle":"2022-05-22T11:38:37.088396Z","shell.execute_reply.started":"2022-05-22T11:38:37.080788Z","shell.execute_reply":"2022-05-22T11:38:37.087580Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class block(nn.Module):\n    def __init__(\n        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n    ):\n        super(block, self).__init__()\n        self.expansion = 4\n        self.conv1 = nn.Conv2d(\n            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n        self.conv2 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n        self.conv3 = nn.Conv2d(\n            intermediate_channels,\n            intermediate_channels * self.expansion,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False\n        )\n        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x.clone()\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, image_channels, num_classes):\n        super(ResNet, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Essentially the entire ResNet architecture are in these 4 lines below\n        self.layer1 = self._make_layer(\n            block, layers[0], intermediate_channels=64, stride=1\n        )\n        self.layer2 = self._make_layer(\n            block, layers[1], intermediate_channels=128, stride=2\n        )\n        self.layer3 = self._make_layer(\n            block, layers[2], intermediate_channels=256, stride=2\n        )\n        self.layer4 = self._make_layer(\n            block, layers[3], intermediate_channels=512, stride=2\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * 4, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n\n        return x\n\n    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n        identity_downsample = None\n        layers = []\n\n        if stride != 1 or self.in_channels != intermediate_channels * 4:\n            identity_downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.in_channels,\n                    intermediate_channels * 4,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False\n                ),\n                nn.BatchNorm2d(intermediate_channels * 4),\n            )\n\n        layers.append(\n            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n        )\n\n        self.in_channels = intermediate_channels * 4\n\n\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(self.in_channels, intermediate_channels))\n\n        return nn.Sequential(*layers)\n\n\n# def ResNet50(img_channel=3, num_classes=1000):\n#     return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n\n\n# def ResNet101(img_channel=3, num_classes=1000):\n#     return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n\n\n# def ResNet152(img_channel=3, num_classes=1000):\n#     return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.091538Z","iopub.execute_input":"2022-05-22T11:38:37.091746Z","iopub.status.idle":"2022-05-22T11:38:37.115023Z","shell.execute_reply.started":"2022-05-22T11:38:37.091715Z","shell.execute_reply":"2022-05-22T11:38:37.114254Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate(param, model):\n    \n    run_epochs(param, model)\n        \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in valloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = (100*correct/total)\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.116163Z","iopub.execute_input":"2022-05-22T11:38:37.116825Z","iopub.status.idle":"2022-05-22T11:38:37.127312Z","shell.execute_reply.started":"2022-05-22T11:38:37.116783Z","shell.execute_reply":"2022-05-22T11:38:37.126507Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def run_epochs(param,model):\n    model = model.to(device)\n    best_model = model\n    #criterion = getattr(nn, param['criterion'])()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr=param['learning_rate'])\n    num_epochs = param['epochs']\n    \n    step = 0\n    losses = []\n    accuracies = []\n    best_acc = 0\n    accuracy = 0\n\n    torch.cuda.empty_cache()\n\n    for epoch in range(num_epochs):\n        train_loss = 0.0\n        train_acc = 0.0\n\n        for i, (images,labels) in enumerate(trainloader):\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            losses.append(loss.item())            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            _, predictions = outputs.max(1)\n            num_correct = (predictions == labels).sum()\n            running_train_acc = float(num_correct)/float(images.shape[0])\n            accuracies.append(running_train_acc)\n            \n            if best_acc < running_train_acc:\n                best_model = model\n                accuracy = running_train_acc\n    \n        print(\"Accuracy for epoch {} = {}\".format(epoch+1, running_train_acc*100))\n                \n#             train_acc += running_train_acc\n#             train_loss += loss.item()\n#             avg_train_acc = train_acc / len(trainloader)\n#             avg_train_loss = train_loss / len(trainloader)\n\n    model = best_model\n            \n    return losses, accuracies, accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.128386Z","iopub.execute_input":"2022-05-22T11:38:37.128903Z","iopub.status.idle":"2022-05-22T11:38:37.142418Z","shell.execute_reply.started":"2022-05-22T11:38:37.128823Z","shell.execute_reply":"2022-05-22T11:38:37.141740Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n    model = ResNet(block, [2,2,2,2], 3, 2)\n    \n    params = {\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n        'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n        'epochs': 2\n        #'criterion': trial.suggest_categorical(\"criterion\", [\"NLLLoss\", \"CrossEntropyLoss\", \"GaussianNLLLoss\"])\n    }   \n    \n    accuracy = train_and_evaluate(params, model)\n    \n    return accuracy\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.144727Z","iopub.execute_input":"2022-05-22T11:38:37.145530Z","iopub.status.idle":"2022-05-22T11:38:37.151850Z","shell.execute_reply.started":"2022-05-22T11:38:37.145494Z","shell.execute_reply":"2022-05-22T11:38:37.151186Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# EPOCHS = 30\n\n# study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n# study.optimize(objective, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T14:05:10.134717Z","iopub.execute_input":"2022-05-21T14:05:10.135379Z","iopub.status.idle":"2022-05-21T14:05:10.139949Z","shell.execute_reply.started":"2022-05-21T14:05:10.135333Z","shell.execute_reply":"2022-05-21T14:05:10.139112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_model(model, trainloader):\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in trainloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n\n        accuracy = (100*correct/total)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.153425Z","iopub.execute_input":"2022-05-22T11:38:37.154788Z","iopub.status.idle":"2022-05-22T11:38:37.162686Z","shell.execute_reply.started":"2022-05-22T11:38:37.154753Z","shell.execute_reply":"2022-05-22T11:38:37.161954Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"optimizer\": \"RMSprop\",\n    \"learning_rate\": 0.0003264,\n    \"epochs\": 2\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:51:10.378480Z","iopub.execute_input":"2022-05-22T11:51:10.379024Z","iopub.status.idle":"2022-05-22T11:51:10.384597Z","shell.execute_reply.started":"2022-05-22T11:51:10.378984Z","shell.execute_reply":"2022-05-22T11:51:10.382185Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nmodel = ResNet(block, [2,2,2,2], 3, 2)\n\nlosses, accuracies, accuracy = run_epochs(params,model)\n\nprint(\"Accuracy = \", accuracy)\nprint(\"--- %s minutes ---\" % ((time.time() - start_time)/60))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T14:04:18.369396Z","iopub.status.idle":"2022-05-21T14:04:18.370042Z","shell.execute_reply.started":"2022-05-21T14:04:18.369774Z","shell.execute_reply":"2022-05-21T14:04:18.3698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(losses):\n    plt.plot(losses, '-bx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.171973Z","iopub.execute_input":"2022-05-22T11:38:37.172460Z","iopub.status.idle":"2022-05-22T11:38:37.178397Z","shell.execute_reply.started":"2022-05-22T11:38:37.172413Z","shell.execute_reply":"2022-05-22T11:38:37.177675Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(accuracy):\n    plt.plot(accuracies,'-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs Number of Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:38:37.179739Z","iopub.execute_input":"2022-05-22T11:38:37.180237Z","iopub.status.idle":"2022-05-22T11:38:37.186347Z","shell.execute_reply.started":"2022-05-22T11:38:37.180201Z","shell.execute_reply":"2022-05-22T11:38:37.185652Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plot_losses(losses)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T18:47:47.901206Z","iopub.execute_input":"2022-05-21T18:47:47.901967Z","iopub.status.idle":"2022-05-21T18:47:47.921031Z","shell.execute_reply.started":"2022-05-21T18:47:47.90193Z","shell.execute_reply":"2022-05-21T18:47:47.920098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(accuracies)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T14:04:18.385471Z","iopub.status.idle":"2022-05-21T14:04:18.386211Z","shell.execute_reply.started":"2022-05-21T14:04:18.385979Z","shell.execute_reply":"2022-05-21T14:04:18.386003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T14:04:18.388008Z","iopub.status.idle":"2022-05-21T14:04:18.388749Z","shell.execute_reply.started":"2022-05-21T14:04:18.388507Z","shell.execute_reply":"2022-05-21T14:04:18.388532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print('Test accuracy = %f' % check_model(model, testloader))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T14:41:50.00936Z","iopub.execute_input":"2022-05-21T14:41:50.009627Z","iopub.status.idle":"2022-05-21T14:42:18.334124Z","shell.execute_reply.started":"2022-05-21T14:41:50.009596Z","shell.execute_reply":"2022-05-21T14:42:18.332633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Validation accuracy = %f' % check_model(models['model1'],valloader))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T15:48:08.197433Z","iopub.execute_input":"2022-05-21T15:48:08.197905Z","iopub.status.idle":"2022-05-21T15:48:08.214163Z","shell.execute_reply.started":"2022-05-21T15:48:08.197872Z","shell.execute_reply":"2022-05-21T15:48:08.213056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration options\nk_folds = 5\nepochs = 2\nloss_function = nn.CrossEntropyLoss()\n\n# For fold results\nresults = {}\n\n# Set fixed random number seed\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:51:16.335288Z","iopub.execute_input":"2022-05-22T11:51:16.335878Z","iopub.status.idle":"2022-05-22T11:51:16.342906Z","shell.execute_reply.started":"2022-05-22T11:51:16.335838Z","shell.execute_reply":"2022-05-22T11:51:16.341168Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nkfold = KFold(n_splits=k_folds, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:51:18.275165Z","iopub.execute_input":"2022-05-22T11:51:18.275414Z","iopub.status.idle":"2022-05-22T11:51:18.280330Z","shell.execute_reply.started":"2022-05-22T11:51:18.275383Z","shell.execute_reply":"2022-05-22T11:51:18.278500Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"models = {}\nc = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:51:19.353236Z","iopub.execute_input":"2022-05-22T11:51:19.353504Z","iopub.status.idle":"2022-05-22T11:51:19.358316Z","shell.execute_reply.started":"2022-05-22T11:51:19.353473Z","shell.execute_reply":"2022-05-22T11:51:19.357655Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# K-fold Cross Validation model evaluation\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n\n    # Print\n    print(f'FOLD {fold}')\n    print('--------------------------------')\n\n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n\n    # Define data loaders for training and testing data in this fold\n    trainloader = torch.utils.data.DataLoader(\n                      dataset, \n                      batch_size=10, sampler=train_subsampler)\n    testloader = torch.utils.data.DataLoader(\n                      dataset,\n                      batch_size=10, sampler=test_subsampler)\n\n    # Init the neural network\n    model = ResNet(block, [2,2,2,2], 3, 2)\n\n    # Run the training loop for defined number of epochs\n    losses, accuracies, accuracy = run_epochs(params,model)\n\n    # Process is complete.\n    print('Training process has finished. Saving trained model.')\n    print('--------------------------------')\n    models['model'+str(c)] = model\n    c += 1","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:52:11.360789Z","iopub.execute_input":"2022-05-22T11:52:11.361496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(models, data):\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        out = 0\n\n\n        \n        for images,labels in trainloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            prediction = []\n            for i in range(5):\n                outputs = models['model'+str(i+1)](images)\n                _, predicted = torch.max(outputs.data, 1)\n                prediction += predicted \n            \n            prediction = [x/5 for x in prediction]\n            prediction = [(1 if i>0.5 else 0) for i in prediction]\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            \n            \n            \n#             out = 0\n#             for i in range(5):\n#                 outputs = models['model'+str(i+1)](images)\n#                 outputs = outputs.sigmoid()\n#                 out = out + outputs\n#             predictions = (out/5) > 0.5\n#             total += labels.size(0)\n               \n#             y_pred.append(predictions)\n#             y_true.append(labels)\n#         y_pred = y_pred.cpu().numpy()\n#         y_true = y_true.numpy\n#         y_pred = y_pred.astype(np.int64)\n#         y_true = y_true.astype(np.int64)\n#         y_pred = y_pred.reshape[-1]\n#         y_true = y_true.reshape[-1]\n#         accuracy = (100*accuracy_score(y_true,y_pred))\n    accuracy = (100*correct/total)\n    \n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = predict(models,data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    torch.save(models['model'+str(i+1)].state_dict(), f'model{i+1}.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T22:07:38.787778Z","iopub.status.idle":"2022-05-21T22:07:38.788482Z","shell.execute_reply.started":"2022-05-21T22:07:38.788217Z","shell.execute_reply":"2022-05-21T22:07:38.788244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = y1_pred\ny_true = y1_true","metadata":{"execution":{"iopub.status.busy":"2022-05-21T20:58:47.610823Z","iopub.execute_input":"2022-05-21T20:58:47.611301Z","iopub.status.idle":"2022-05-21T20:58:47.616032Z","shell.execute_reply.started":"2022-05-21T20:58:47.61125Z","shell.execute_reply":"2022-05-21T20:58:47.615255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1_pred = y_pred\ny1_true = y_true\n\ny_pred = torch.cat(y_pred)\ny_true = torch.cat(y_true)\ny_pred = y_pred.cpu().numpy()\ny_true = y_true.cpu().numpy()\ny_pred = y_pred.astype(np.int64)\ny_true = y_true.astype(np.int64)\ny_pred = y_pred.reshape(-1)\ny_true = y_true.reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T20:58:48.023327Z","iopub.execute_input":"2022-05-21T20:58:48.02394Z","iopub.status.idle":"2022-05-21T20:58:48.032445Z","shell.execute_reply.started":"2022-05-21T20:58:48.023901Z","shell.execute_reply":"2022-05-21T20:58:48.031147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = (100*accuracy_score(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T20:59:34.338755Z","iopub.execute_input":"2022-05-21T20:59:34.339626Z","iopub.status.idle":"2022-05-21T20:59:34.365899Z","shell.execute_reply.started":"2022-05-21T20:59:34.339585Z","shell.execute_reply":"2022-05-21T20:59:34.365006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}