{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(os.path.join(dirname))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T18:57:28.003903Z","iopub.execute_input":"2022-05-23T18:57:28.004552Z","iopub.status.idle":"2022-05-23T18:57:32.057681Z","shell.execute_reply.started":"2022-05-23T18:57:28.004464Z","shell.execute_reply":"2022-05-23T18:57:32.056948Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"traindir = '../input/chest-xray-pneumonia/chest_xray/train'\ntestdir = '../input/chest-xray-pneumonia/chest_xray/test'\nvaldir = '../input/chest-xray-pneumonia/chest_xray/val'","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:32.059608Z","iopub.execute_input":"2022-05-23T18:57:32.059879Z","iopub.status.idle":"2022-05-23T18:57:32.063730Z","shell.execute_reply.started":"2022-05-23T18:57:32.059844Z","shell.execute_reply":"2022-05-23T18:57:32.062781Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_count_p = len(next(os.walk(traindir+'/PNEUMONIA'))[2])\ntrain_count_n = len(next(os.walk(traindir+'/NORMAL'))[2])\nprint(\"Pneumonia Train Number = \", train_count_p)\nprint(\"Normal Train Number = \", train_count_n)\n\ntest_count_p = len(next(os.walk(testdir+'/PNEUMONIA'))[2])\ntest_count_n = len(next(os.walk(testdir+'/NORMAL'))[2])\nprint(\"Pneumonia Test Number = \",test_count_p)\nprint(\"Normal Test Number = \", test_count_n)\n\nval_count_p = len(next(os.walk(valdir+'/PNEUMONIA'))[2])\nval_count_p = len(next(os.walk(valdir+'/PNEUMONIA'))[2])\nprint(\"Normal Val Number = \", test_count_n)\nprint(\"Normal Val Number = \", test_count_n)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:32.065081Z","iopub.execute_input":"2022-05-23T18:57:32.065634Z","iopub.status.idle":"2022-05-23T18:57:32.095602Z","shell.execute_reply.started":"2022-05-23T18:57:32.065597Z","shell.execute_reply":"2022-05-23T18:57:32.094831Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"- P test Number =  3875\n- N test number =  1341\n- P test Number =  390\n- N test number =  234\n- P test Number =  8\n- N test number =  8","metadata":{}},{"cell_type":"markdown","source":"## Plotting Sample Pneumonia Images","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.figure(figsize=(15, 5))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(testdir+'/PNEUMONIA', os.listdir(testdir+'/PNEUMONIA')[i]))\n    plt.title('Pneumonia')\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:32.097589Z","iopub.execute_input":"2022-05-23T18:57:32.097827Z","iopub.status.idle":"2022-05-23T18:57:33.765425Z","shell.execute_reply.started":"2022-05-23T18:57:32.097795Z","shell.execute_reply":"2022-05-23T18:57:33.764671Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Sample Normal Images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = plt.imread(os.path.join(testdir+'/NORMAL', os.listdir(testdir+'/NORMAL')[i]))\n    plt.title('Normal')\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:33.766439Z","iopub.execute_input":"2022-05-23T18:57:33.766661Z","iopub.status.idle":"2022-05-23T18:57:36.117323Z","shell.execute_reply.started":"2022-05-23T18:57:33.766634Z","shell.execute_reply":"2022-05-23T18:57:36.116639Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import glob\n\ntrain_p = glob.glob(traindir+'/PNEUMONIA/*jpeg')\ntrain_n = glob.glob(traindir+'/NORMAL/*jpeg')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:36.118360Z","iopub.execute_input":"2022-05-23T18:57:36.118702Z","iopub.status.idle":"2022-05-23T18:57:36.144874Z","shell.execute_reply.started":"2022-05-23T18:57:36.118669Z","shell.execute_reply":"2022-05-23T18:57:36.144252Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(np.concatenate([[0]*len(train_n), [1]*len(train_p)]), columns=[\"class\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:36.146177Z","iopub.execute_input":"2022-05-23T18:57:36.146439Z","iopub.status.idle":"2022-05-23T18:57:36.154935Z","shell.execute_reply.started":"2022-05-23T18:57:36.146407Z","shell.execute_reply":"2022-05-23T18:57:36.154163Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Comparing Pneumonia and Normal Images","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(15,10))\nsns.countplot(data['class'], data=data, palette='rocket')\nplt.title('PNEUMONIA vs NORMAL')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:36.156252Z","iopub.execute_input":"2022-05-23T18:57:36.156472Z","iopub.status.idle":"2022-05-23T18:57:37.220223Z","shell.execute_reply.started":"2022-05-23T18:57:36.156443Z","shell.execute_reply":"2022-05-23T18:57:37.219492Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Transforming Images \n- Resizing \n- Normalizing \n- Applying Random Rotations","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\ntrain_trnsf = transforms.Compose([transforms.RandomRotation((-20,20)),\n                                 transforms.Resize((224,224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n\ntest_trnsf = transforms.Compose([transforms.Resize((224,224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:37.221506Z","iopub.execute_input":"2022-05-23T18:57:37.222220Z","iopub.status.idle":"2022-05-23T18:57:38.853013Z","shell.execute_reply.started":"2022-05-23T18:57:37.222167Z","shell.execute_reply":"2022-05-23T18:57:38.852184Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder \ntrain_ds = ImageFolder(traindir, train_trnsf)\ntest_ds = ImageFolder(testdir, test_trnsf)\nval_ds = ImageFolder(valdir, test_trnsf)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:38.855901Z","iopub.execute_input":"2022-05-23T18:57:38.856295Z","iopub.status.idle":"2022-05-23T18:57:39.768792Z","shell.execute_reply.started":"2022-05-23T18:57:38.856254Z","shell.execute_reply":"2022-05-23T18:57:39.768035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"img, labels = train_ds[0]\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:39.769917Z","iopub.execute_input":"2022-05-23T18:57:39.770151Z","iopub.status.idle":"2022-05-23T18:57:39.926650Z","shell.execute_reply.started":"2022-05-23T18:57:39.770120Z","shell.execute_reply":"2022-05-23T18:57:39.925816Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.classes\nprint(class_names)\nprint(train_ds.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:39.927995Z","iopub.execute_input":"2022-05-23T18:57:39.928332Z","iopub.status.idle":"2022-05-23T18:57:39.934815Z","shell.execute_reply.started":"2022-05-23T18:57:39.928293Z","shell.execute_reply":"2022-05-23T18:57:39.934119Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 64\ntrainloader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\ntestloader = DataLoader(test_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\nvalloader = DataLoader(val_ds, batch_size*2, shuffle = True, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:39.935987Z","iopub.execute_input":"2022-05-23T18:57:39.936644Z","iopub.status.idle":"2022-05-23T18:57:39.943179Z","shell.execute_reply.started":"2022-05-23T18:57:39.936607Z","shell.execute_reply":"2022-05-23T18:57:39.942487Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:39.944359Z","iopub.execute_input":"2022-05-23T18:57:39.944992Z","iopub.status.idle":"2022-05-23T18:57:39.997503Z","shell.execute_reply.started":"2022-05-23T18:57:39.944957Z","shell.execute_reply":"2022-05-23T18:57:39.996676Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:39.998810Z","iopub.execute_input":"2022-05-23T18:57:39.999100Z","iopub.status.idle":"2022-05-23T18:57:40.790129Z","shell.execute_reply.started":"2022-05-23T18:57:39.999065Z","shell.execute_reply":"2022-05-23T18:57:40.789411Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Custom CNN Network ","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, params):\n        super().__init__()\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(3,64, kernel_size=3, stride=1, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=64, out_channels=128,kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            \n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            \n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            \n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding = 1),\n            \n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4,stride=2, padding=1), #(512*7*7)\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding = 1)\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(512*7*7, 256),\n            nn.Linear(256,128),\n            nn.Linear(128,64),\n            nn.Linear(64,2)\n        )\n    \n    def forward(self, x):\n        out = self.conv2(x)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:40.791555Z","iopub.execute_input":"2022-05-23T18:57:40.791797Z","iopub.status.idle":"2022-05-23T18:57:40.804771Z","shell.execute_reply.started":"2022-05-23T18:57:40.791763Z","shell.execute_reply":"2022-05-23T18:57:40.804129Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Function for training and evaluating models with different parameters for optuna to search for the best one ","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate(param, model):\n    \n    run_epochs(param, model)\n        \n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in valloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = (100*correct/total)\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-23T18:57:40.807091Z","iopub.execute_input":"2022-05-23T18:57:40.807792Z","iopub.status.idle":"2022-05-23T18:57:40.815736Z","shell.execute_reply.started":"2022-05-23T18:57:40.807750Z","shell.execute_reply":"2022-05-23T18:57:40.815003Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Defining the objective function that tries and checks the accuracy of the model with different learning rates and optimizers for finding the best hyperparameters","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n        'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n        #'criterion': trial.suggest_categorical(\"criterion\", [\"NLLLoss\", \"CrossEntropyLoss\", \"GaussianNLLLoss\"])\n    }\n    \n    \n    model = Net(params)\n    \n    accuracy = train_and_evaluate(params, model)\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:05:00.531427Z","iopub.status.idle":"2022-05-10T13:05:00.532053Z","shell.execute_reply.started":"2022-05-10T13:05:00.531817Z","shell.execute_reply":"2022-05-10T13:05:00.531841Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Executing the optuna study function that expermiments with different hyperparameters and finds the one with the maximum accuracy","metadata":{}},{"cell_type":"code","source":"EPOCHS = 30\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\nstudy.optimize(objective, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:05:00.533296Z","iopub.status.idle":"2022-05-10T13:05:00.533936Z","shell.execute_reply.started":"2022-05-10T13:05:00.533687Z","shell.execute_reply":"2022-05-10T13:05:00.533712Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using the best hyperparameters found by optuna","metadata":{}},{"cell_type":"code","source":"params = {\n    \"optimizer\": \"Adam\",\n    \"learning_rate\": 1.025e-05,\n}\n\nmodel = Net(params)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:25:48.584567Z","iopub.execute_input":"2022-05-23T19:25:48.585094Z","iopub.status.idle":"2022-05-23T19:25:48.748905Z","shell.execute_reply.started":"2022-05-23T19:25:48.585044Z","shell.execute_reply":"2022-05-23T19:25:48.748134Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Function to train the model","metadata":{}},{"cell_type":"code","source":"def run_epochs(param,model):\n    model = model.to(device)\n    best_model = model\n    #criterion = getattr(nn, param['criterion'])()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr=param['learning_rate'])\n    num_epochs = 8\n    \n    step = 0\n    losses = []\n    train_loss = []\n    accuracies = []\n    best_acc = 0\n    accuracy = 0\n\n    torch.cuda.empty_cache()\n\n    for epoch in range(num_epochs):\n        \n        running_accuracy = []\n        \n        for i, (images,labels) in enumerate(trainloader):\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            losses.append(loss.item())            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            _, predictions = outputs.max(1)\n            num_correct = (predictions == labels).sum()\n            running_train_acc = float(num_correct)/float(images.shape[0])\n            running_accuracy.append(running_train_acc)\n                \n        train_loss.append(sum(losses)/len(losses))\n        accuracy = sum(running_accuracy) / len(running_accuracy)\n        accuracies.append(accuracy)\n        print(\"Accuracy for epoch {} = {}\".format(epoch+1, accuracy*100))        \n#             train_acc += running_train_acc\n#             train_loss += loss.item()\n#             avg_train_acc = train_acc / len(trainloader)\n#             avg_train_loss = train_loss / len(trainloader)\n            \n    return train_loss, accuracies, model","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:24:55.631571Z","iopub.execute_input":"2022-05-23T19:24:55.632282Z","iopub.status.idle":"2022-05-23T19:24:55.641951Z","shell.execute_reply.started":"2022-05-23T19:24:55.632240Z","shell.execute_reply":"2022-05-23T19:24:55.641278Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nlosses, accuracies, model = run_epochs(params,model)\n\nprint(\"--- %s minutes ---\" % ((time.time() - start_time)/60))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:25:51.536138Z","iopub.execute_input":"2022-05-23T19:25:51.536900Z","iopub.status.idle":"2022-05-23T19:41:24.206187Z","shell.execute_reply.started":"2022-05-23T19:25:51.536861Z","shell.execute_reply":"2022-05-23T19:41:24.205329Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Function to Check the model's accuracy with other data","metadata":{}},{"cell_type":"code","source":"def check_model(model, trainloader):\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in trainloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n\n        accuracy = (100*correct/total)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:25:51.302937Z","iopub.execute_input":"2022-05-23T19:25:51.303873Z","iopub.status.idle":"2022-05-23T19:25:51.311536Z","shell.execute_reply.started":"2022-05-23T19:25:51.303828Z","shell.execute_reply":"2022-05-23T19:25:51.310896Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the losses","metadata":{}},{"cell_type":"code","source":"def plot_losses(losses):\n    plt.plot(losses, '-bx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.title('Loss vs Number of Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:24.208494Z","iopub.execute_input":"2022-05-23T19:41:24.208934Z","iopub.status.idle":"2022-05-23T19:41:24.214278Z","shell.execute_reply.started":"2022-05-23T19:41:24.208890Z","shell.execute_reply":"2022-05-23T19:41:24.213383Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"plot_losses(losses)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:24.215327Z","iopub.execute_input":"2022-05-23T19:41:24.215627Z","iopub.status.idle":"2022-05-23T19:41:24.422852Z","shell.execute_reply.started":"2022-05-23T19:41:24.215593Z","shell.execute_reply":"2022-05-23T19:41:24.422169Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the accuracies","metadata":{}},{"cell_type":"code","source":"def plot_accuracies(accuracy):\n    plt.plot(accuracies,'-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs Number of Epochs')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:24.425006Z","iopub.execute_input":"2022-05-23T19:41:24.425296Z","iopub.status.idle":"2022-05-23T19:41:24.429639Z","shell.execute_reply.started":"2022-05-23T19:41:24.425260Z","shell.execute_reply":"2022-05-23T19:41:24.428877Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(accuracies)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:24.431108Z","iopub.execute_input":"2022-05-23T19:41:24.431406Z","iopub.status.idle":"2022-05-23T19:41:24.613707Z","shell.execute_reply.started":"2022-05-23T19:41:24.431372Z","shell.execute_reply":"2022-05-23T19:41:24.613023Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print('Validation accuracy = %f' % check_model(model,valloader))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:34.372081Z","iopub.execute_input":"2022-05-23T19:41:34.372640Z","iopub.status.idle":"2022-05-23T19:41:34.999099Z","shell.execute_reply.started":"2022-05-23T19:41:34.372596Z","shell.execute_reply":"2022-05-23T19:41:34.998262Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:24.614925Z","iopub.execute_input":"2022-05-23T19:41:24.615374Z","iopub.status.idle":"2022-05-23T19:41:24.754606Z","shell.execute_reply.started":"2022-05-23T19:41:24.615334Z","shell.execute_reply":"2022-05-23T19:41:24.753794Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print('Test accuracy = %f' % check_model(model, testloader))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T19:41:24.755839Z","iopub.execute_input":"2022-05-23T19:41:24.756192Z","iopub.status.idle":"2022-05-23T19:41:34.370473Z","shell.execute_reply.started":"2022-05-23T19:41:24.756155Z","shell.execute_reply":"2022-05-23T19:41:34.368823Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load(model.state_dict(), 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T13:03:32.845913Z","iopub.execute_input":"2022-05-16T13:03:32.846502Z","iopub.status.idle":"2022-05-16T13:03:33.036153Z","shell.execute_reply.started":"2022-05-16T13:03:32.846461Z","shell.execute_reply":"2022-05-16T13:03:33.033821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}